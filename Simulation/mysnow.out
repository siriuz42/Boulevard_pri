
R version 3.4.0 (2017-04-21) -- "You Stupid Darkness"
Copyright (C) 2017 The R Foundation for Statistical Computing
Platform: x86_64-redhat-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> 
> # Looking for what machines are available to use.
> library(snowfall)
> pbsnodefile = Sys.getenv("PBS_NODEFILE")
> machines <- scan(pbsnodefile, what="")
> print(machines)
 [1] "compute-2-9" "compute-2-9" "compute-2-9" "compute-2-9" "compute-2-9"
 [6] "compute-2-9" "compute-2-9" "compute-2-9" "compute-2-8" "compute-2-8"
[11] "compute-2-8" "compute-2-8" "compute-2-8" "compute-2-8" "compute-2-8"
[16] "compute-2-8" "compute-2-4" "compute-2-4" "compute-2-4" "compute-2-4"
[21] "compute-2-4" "compute-2-4" "compute-2-4" "compute-2-4" "compute-2-2"
[26] "compute-2-2" "compute-2-2" "compute-2-2" "compute-2-2" "compute-2-2"
[31] "compute-2-2" "compute-2-2" "compute-1-8" "compute-1-8" "compute-1-8"
[36] "compute-1-8" "compute-1-8" "compute-1-8" "compute-1-8" "compute-1-8"
[41] "compute-1-7" "compute-1-7" "compute-1-7" "compute-1-7" "compute-1-7"
[46] "compute-1-7" "compute-1-7" "compute-1-7"
> nmach = length(machines)
> nmach
[1] 48
> 
> # Initializing the nodes
> sfInit(parallel=TRUE,type='SOCK',cpus=nmach,socketHosts=machines)
R Version:  R version 3.4.0 (2017-04-21) 

> 
> 
> #################################################################################
> #  All of the above 'R --vanilla...' is for the cluster
> #  All of the below 'R --vanilla...' is an R file
> #  This is the beginning of a 'regular' R file
> #################################################################################
> sfSource("honestRpart.R")
Source honestRpart.R loaded.

> library(rpart)

> library(treeClust)

> library(plotrix)

> honest.rpart.structure <- function(X, Y, method = "standard", 
+     structY = NULL, leaf.size = 3, diameter.test = NULL) {
+     n <- nrow(X)
+     .... [TRUNCATED] 

> honest.rpart <- function(X, Y, method = "standard", 
+     structY = NULL, subset = NULL, leaf.size = 3, diameter.test = NULL) {
+     colnames(X) < .... [TRUNCATED] 

> honest.rpart.predict <- function(tree, newdata) {
+     if (is.vector(newdata)) {
+         newdata = matrix(newdata, nrow = 1)
+     }
+     colnam .... [TRUNCATED] 

> honest.rpart.predict.weight <- function(tree, newdata) {
+     if (is.vector(newdata)) {
+         newdata = matrix(newdata, nrow = 1)
+     }
+     .... [TRUNCATED] 

> predict.boulevard <- function(blv, X) {
+     ntree <- length(blv$trees)
+     lambda <- blv$lambda
+     ans <- rep(0, nrow(X))
+     for (b in 1:n .... [TRUNCATED] 

> predict.boulevard.variance <- function(blv, newdata, 
+     narrow = FALSE) {
+     ntree <- length(blv$trees)
+     lambda <- blv$lambda
+     ans  .... [TRUNCATED] 

> boulevard <- function(X, Y, ntree = 1000, lambda = 0.8, 
+     subsample = 0.8, xtest = NULL, ytest = NULL, leaf.size = 10, 
+     method = "random" .... [TRUNCATED] 
> 
> suffix <- format(Sys.time(), "%y%m%d%H%M%S")
> ######## HERE BEGINS THE SIMULATION ########
> 
> pred <- function(X) {
+     return(X[, 1] + 3*X[, 2] + X[, 3]^2 + 2*X[, 4]*X[, 5])
+ }
> 
> error <- function(n, d = 1) {
+     return(runif(n, -d, d))
+ }
> 
> node.work <- function(dummy, n, d, subsample, leaf.size, ntree, lambda = 0.5) {
+     xtrain <- matrix(runif(d*n), nrow=n)
+     ytrain <- pred(xtrain) + error(n)
+     blv <- boulevard(xtrain, ytrain, ntree=ntree, subsample=subsample, lambda = lambda,
+                      leaf.size=leaf.size, method="random") 
+     return(predict.boulevard(blv, xtest)) 
+ }
> 
> d <- 5
> n <- 2000
> subsample <- 0.5 
> leaf.size <- 10  
> ntree <- 1000
> lambda <- 0.5
> 
> ntest <- 10
> xtest <- t(matrix(c(0.5, 0.5, 0.5, 0.5, 0.5,
+                     0.2, 0.2, 0.2, 0.2, 0.2,
+                     0.1, 0.9, 0.1, 0.9, 0.1,
+                     0.1, 0.1, 0.9, 0.9, 0.9,
+                     0.9, 0.1, 0.1, 0.1, 0.9,
+                     0.5, 0.1, 0.9, 0.1, 0.5,
+                     0.3, 0.2, 0.7, 0.8, 0.6,
+                     0.4, 0.2, 0.3, 0.6, 0.7,
+                     0.2, 0.7, 0.8, 0.3, 0.5,
+                     0.3, 0.6, 0.4, 0.9, 0.5), nrow=d))
> 
> sfExportAll()
> 
> result <- sfSapply(1:100, node.work, 
+                    n=n, d=d, subsample=subsample, leaf.size=leaf.size, ntree=ntree)
> result <- t(result)
> save(result, file=paste("result_", suffix, ".RData", sep=""))
> 
> xtrain <- matrix(runif(d*n), nrow=n)
> ytrain <- pred(xtrain) + error(n)
> blv <- boulevard(xtrain, ytrain, ntree=ntree, subsample=subsample, lambda = lambda,
+                  leaf.size=leaf.size, method="random") 
Training: 50 
Training: 100 
Training: 150 
Training: 200 
Training: 250 
Training: 300 
Training: 350 
Training: 400 
Training: 450 
Training: 500 
Training: 550 
Training: 600 
Training: 650 
Training: 700 
Training: 750 
Training: 800 
Training: 850 
Training: 900 
Training: 950 
Training: 1000 
>                  
> est.var <- predict.boulevard.variance(blv, newdata = xtest)
> ci.width <- 1.96*sqrt(est.var)*sqrt(2)
> blv.pred <- predict.boulevard(blv, xtest)
> truth <- pred(xtest)
> 
> # plotmax <- max(truth, blv.pred+ci.width, blv.pred-ci.width, ytrain[1:ntest])
> # plotmin <- min(truth, blv.pred+ci.width, blv.pred-ci.width, ytrain[1:ntest])
> 
> 
> plotmax <- max(truth, blv.pred+ci.width, blv.pred-ci.width, result)
> plotmin <- min(truth, blv.pred+ci.width, blv.pred-ci.width, result)
> 
> postscript(file=paste("fig_", suffix, ".eps", sep=""))
> boxplot(result, ylim=c(plotmin, plotmax), xlab="Test Pts")
> plotCI(blv.pred, uiw = ci.width, 
+        add=TRUE, col="red", cex=1, slty=1)
> points(truth, col="blue", pch=2)
> dev.off()
null device 
          1 
> sfStop()
> 
> 
